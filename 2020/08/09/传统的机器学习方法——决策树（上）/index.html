<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>传统的机器学习方法——决策树（上） | milkcoffee</title>
  <meta name="keywords" content="">
  <meta name="description" content="传统的机器学习方法——决策树（上） | milkcoffee">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="description" content="hetingting的个人博客">
<meta property="og:type" content="website">
<meta property="og:title" content="about">
<meta property="og:url" content="http://yoursite.com/about/index.html">
<meta property="og:site_name" content="milkcoffee">
<meta property="og:description" content="hetingting的个人博客">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2020-08-08T13:19:19.000Z">
<meta property="article:modified_time" content="2020-08-08T13:19:19.969Z">
<meta property="article:author" content="和婷婷">
<meta property="article:tag" content="个人博客，学习，生活">
<meta name="twitter:card" content="summary">


<link rel="icon" href="/img/1.jpg">

<link href="/css/style.css?v=1.1.0" rel="stylesheet">

<link href="/css/hl_theme/atom-light.css?v=1.1.0" rel="stylesheet">

<link href="//cdn.jsdelivr.net/npm/animate.css@4.1.0/animate.min.css" rel="stylesheet">

<script src="//cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.min.js"></script>
<script src="/js/titleTip.js?v=1.1.0" ></script>

<script src="//cdn.jsdelivr.net/npm/highlightjs@9.16.2/highlight.pack.min.js"></script>
<script>
    hljs.initHighlightingOnLoad();
</script>

<script src="//cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.min.js"></script>



<script src="//cdn.jsdelivr.net/npm/jquery.cookie@1.4.1/jquery.cookie.min.js" ></script>

<script src="/js/iconfont.js?v=1.1.0" ></script>

<meta name="generator" content="Hexo 5.0.0"></head>
<div style="display: none">
  <input class="theme_disqus_on" value="false">
  <input class="theme_preload_comment" value="">
  <input class="theme_blog_path" value="">
  <input id="theme_shortcut" value="true" />
</div>


<body>
<aside class="nav">
    <div class="nav-left">
        <a href="/" class="avatar_target">
    <img class="avatar" src="/img/1.jpg" />
</a>
<div class="author">
    <span>和婷婷</span>
</div>

<div class="icon">
    
        
        <a title="github" href="https://github.com/AITTH" target="_blank">
            
                <svg class="iconfont-svg" aria-hidden="true">
                    <use xlink:href="#icon-github"></use>
                </svg>
            
        </a>
        
    
        
        <a title="csdn" href="https://blog.csdn.net/weixin_49313319" target="_blank">
            
                <svg class="iconfont-svg" aria-hidden="true">
                    <use xlink:href="#icon-csdn"></use>
                </svg>
            
        </a>
        
    
</div>




<ul>
    <li><div class="all active" data-rel="全部文章">全部文章<small>(7)</small></div></li>
    
</ul>
<div class="left-bottom">
    <div class="menus">
    
    
    
    </div>
    <div><a class="about  hasFriend  site_url"  href="/about">关于</a><a style="width: 50%"  class="friends">友链</a></div>
</div>
<input type="hidden" id="yelog_site_posts_number" value="7">

<div style="display: none">
    <span id="busuanzi_value_site_uv"></span>
    <span id="busuanzi_value_site_pv"></span>
</div>

    </div>
    <div class="nav-right">
        <div class="friends-area">
    <div class="friends-title">
        友情链接
        <i class="iconfont icon-left"></i>
    </div>
    <div class="friends-content">
        <ul>
            
        </ul>
    </div>
</div>
        <div class="title-list">
    <div class="right-top">
        <div id="default-panel">
            <i class="iconfont icon-search" data-title="搜索 快捷键 i"></i>
            <div class="right-title">全部文章</div>
            <i class="iconfont icon-file-tree" data-title="切换到大纲视图 快捷键 w"></i>
        </div>
        <div id="search-panel">
            <i class="iconfont icon-left" data-title="返回"></i>
            <input id="local-search-input" />
            <label class="border-line" for="input"></label>
            <i class="iconfont icon-case-sensitive" data-title="大小写敏感"></i>
            <i class="iconfont icon-tag" data-title="标签"></i>
        </div>
        <div id="outline-panel" style="display: none">
            <div class="right-title">大纲</div>
            <i class="iconfont icon-list" data-title="切换到文章列表"></i>
        </div>
    </div>

    <div class="tags-list">
    <input id="tag-search" />
    <div class="tag-wrapper">
        
    </div>

</div>

    
    <nav id="title-list-nav">
        
        <a  class="全部文章 "
           href="/2020/08/22/%E5%B0%8F%E5%8F%91%E7%8E%B0/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="钉钉中的小发现">钉钉中的小发现</span>
            <span class="post-date" title="2020-08-22 08:13:49">2020/08/22</span>
        </a>
        
        <a  class="全部文章 "
           href="/2020/08/16/%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="阅读笔记——基于 CART 决策树的计算机网络课程学生成绩分析">阅读笔记——基于 CART 决策树的计算机网络课程学生成绩分析</span>
            <span class="post-date" title="2020-08-16 19:08:23">2020/08/16</span>
        </a>
        
        <a  class="全部文章 "
           href="/2020/08/15/github%E5%AD%A6%E4%B9%A0%E7%BB%8F%E9%AA%8C/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="修改github中的username">修改github中的username</span>
            <span class="post-date" title="2020-08-15 17:43:11">2020/08/15</span>
        </a>
        
        <a  class="全部文章 "
           href="/2020/08/10/%E4%BC%A0%E7%BB%9F%E7%9A%84%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E2%80%94%E2%80%94%E5%86%B3%E7%AD%96%E6%A0%91%EF%BC%88%E4%B8%8B%EF%BC%89/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="传统的机器学习方法——决策树（下）">传统的机器学习方法——决策树（下）</span>
            <span class="post-date" title="2020-08-10 17:40:25">2020/08/10</span>
        </a>
        
        <a  class="全部文章 "
           href="/2020/08/09/%E4%BC%A0%E7%BB%9F%E7%9A%84%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E2%80%94%E2%80%94%E5%86%B3%E7%AD%96%E6%A0%91%EF%BC%88%E4%B8%8A%EF%BC%89/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="传统的机器学习方法——决策树（上）">传统的机器学习方法——决策树（上）</span>
            <span class="post-date" title="2020-08-09 09:47:01">2020/08/09</span>
        </a>
        
        <a  class="全部文章 "
           href="/2020/08/08/python%E4%B8%AD%E7%9A%84bug/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="python中的bug">python中的bug</span>
            <span class="post-date" title="2020-08-08 20:26:01">2020/08/08</span>
        </a>
        
        <a  class="全部文章 "
           href="/2020/08/02/hello-world/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="Hello World">Hello World</span>
            <span class="post-date" title="2020-08-02 08:23:27">2020/08/02</span>
        </a>
        
        <div id="no-item-tips">

        </div>
    </nav>
    <div id="outline-list">
    </div>
</div>
    </div>
    <div class="hide-list">
        <div class="semicircle" data-title="切换全屏 快捷键 s">
            <div class="brackets first"><</div>
            <div class="brackets">&gt;</div>
        </div>
    </div>
</aside>
<div id="post">
    <div class="pjax">
        <article id="post-传统的机器学习方法——决策树（上）" class="article article-type-post" itemscope itemprop="blogPost">
    
        <h1 class="article-title">传统的机器学习方法——决策树（上）</h1>
    
    <div class="article-meta">
        
        
        
        
    </div>
    <div class="article-meta">
        
            发布时间 : <time class="date" title='最后更新: 2020-08-09 09:52:18'>2020-08-09 09:47</time>
        
    </div>
    <div class="article-meta">
        
        
        <span id="busuanzi_container_page_pv">
            阅读 :<span id="busuanzi_value_page_pv">
                <span class="count-comment">
                    <span class="spinner">
                      <div class="cube1"></div>
                      <div class="cube2"></div>
                    </span>
                </span>
            </span>
        </span>
        
        
    </div>
    
    <div class="toc-ref">
    
        <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#1-%E5%86%B3%E7%AD%96%E6%A0%91%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D"><span class="toc-text">1 决策树模型介绍</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-1-%E5%86%B3%E7%AD%96%E6%A0%91%E6%A8%A1%E5%9E%8B%E6%A6%82%E8%BF%B0"><span class="toc-text">1.1 决策树模型概述</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-2-%E5%86%B3%E7%AD%96%E6%A0%91%E4%B8%8Eif-then%E8%A7%84%E5%88%99"><span class="toc-text">1.2 决策树与if-then规则</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-3-%E5%86%B3%E7%AD%96%E6%A0%91%E4%B8%BB%E8%A6%81%E4%BC%98%E7%82%B9"><span class="toc-text">1.3 决策树主要优点</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-4-%E4%B8%BB%E8%A6%81%E6%AD%A5%E9%AA%A4"><span class="toc-text">1.4 主要步骤</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#2-%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9"><span class="toc-text">2 特征选择</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#2-1-%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9%E9%97%AE%E9%A2%98"><span class="toc-text">2.1 特征选择问题</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-1-%E4%B8%BE%E4%B8%AA%E4%BE%8B%E5%AD%90"><span class="toc-text">2.1.1 举个例子</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-2-%E9%87%8D%E8%A6%81%E5%AE%9A%E4%B9%89"><span class="toc-text">2.2 重要定义</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-1-%E7%86%B5"><span class="toc-text">2.2.1 熵</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-2-%E6%9D%A1%E4%BB%B6%E7%86%B5"><span class="toc-text">2.2.2 条件熵</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-3-%E4%BF%A1%E6%81%AF%E5%A2%9E%E7%9B%8A"><span class="toc-text">2.2.3 信息增益</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-3-%E4%BF%A1%E6%81%AF%E5%A2%9E%E7%9B%8A%E7%9A%84%E7%AE%97%E6%B3%95"><span class="toc-text">2.3 信息增益的算法</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-3-1-%E7%AE%97%E6%B3%95%E8%BF%87%E7%A8%8B"><span class="toc-text">2.3.1 算法过程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-3-2-%E4%B8%BE%E4%B8%AA%E4%BE%8B%E5%AD%90"><span class="toc-text">2.3.2 举个例子</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#3-%E5%86%B3%E7%AD%96%E6%A0%91%E7%9A%84%E7%94%9F%E6%88%90"><span class="toc-text">3 决策树的生成</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#3-1-%E4%BB%8B%E7%BB%8D"><span class="toc-text">3.1 介绍</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-2-ID3%E7%AE%97%E6%B3%95"><span class="toc-text">3.2 ID3算法</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-1-ID3%E7%AE%97%E6%B3%95%E6%A0%B8%E5%BF%83"><span class="toc-text">3.2.1 ID3算法核心</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-2-%E7%AE%97%E6%B3%95%E8%BF%87%E7%A8%8B"><span class="toc-text">3.2.2 算法过程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-3-%E4%B8%BE%E4%B8%AA%E4%BE%8B%E5%AD%90"><span class="toc-text">3.2.3 举个例子</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-4-ID3%E7%AE%97%E6%B3%95%E7%9A%84%E4%B8%8D%E8%B6%B3"><span class="toc-text">3.2.4 ID3算法的不足</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-3-C4-5%E7%AE%97%E6%B3%95"><span class="toc-text">3.3 C4.5算法</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-3-1-C4-5%E7%AE%97%E6%B3%95%E7%9A%84%E4%B8%8D%E8%B6%B3"><span class="toc-text">3.3.1 C4.5算法的不足</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#4-%E6%80%BB%E7%BB%93"><span class="toc-text">4 总结</span></a></li></ol>
    
<style>
    .left-col .switch-btn,
    .left-col .switch-area {
        display: none;
    }
    .toc-level-3 i,
    .toc-level-3 ol {
        display: none !important;
    }
</style>
</div>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>@<div class='inner-toc'><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#1-%E5%86%B3%E7%AD%96%E6%A0%91%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D"><span class="toc-text">1 决策树模型介绍</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-1-%E5%86%B3%E7%AD%96%E6%A0%91%E6%A8%A1%E5%9E%8B%E6%A6%82%E8%BF%B0"><span class="toc-text">1.1 决策树模型概述</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-2-%E5%86%B3%E7%AD%96%E6%A0%91%E4%B8%8Eif-then%E8%A7%84%E5%88%99"><span class="toc-text">1.2 决策树与if-then规则</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-3-%E5%86%B3%E7%AD%96%E6%A0%91%E4%B8%BB%E8%A6%81%E4%BC%98%E7%82%B9"><span class="toc-text">1.3 决策树主要优点</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-4-%E4%B8%BB%E8%A6%81%E6%AD%A5%E9%AA%A4"><span class="toc-text">1.4 主要步骤</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#2-%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9"><span class="toc-text">2 特征选择</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#2-1-%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9%E9%97%AE%E9%A2%98"><span class="toc-text">2.1 特征选择问题</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-1-%E4%B8%BE%E4%B8%AA%E4%BE%8B%E5%AD%90"><span class="toc-text">2.1.1 举个例子</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-2-%E9%87%8D%E8%A6%81%E5%AE%9A%E4%B9%89"><span class="toc-text">2.2 重要定义</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-1-%E7%86%B5"><span class="toc-text">2.2.1 熵</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-2-%E6%9D%A1%E4%BB%B6%E7%86%B5"><span class="toc-text">2.2.2 条件熵</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-3-%E4%BF%A1%E6%81%AF%E5%A2%9E%E7%9B%8A"><span class="toc-text">2.2.3 信息增益</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-3-%E4%BF%A1%E6%81%AF%E5%A2%9E%E7%9B%8A%E7%9A%84%E7%AE%97%E6%B3%95"><span class="toc-text">2.3 信息增益的算法</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-3-1-%E7%AE%97%E6%B3%95%E8%BF%87%E7%A8%8B"><span class="toc-text">2.3.1 算法过程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-3-2-%E4%B8%BE%E4%B8%AA%E4%BE%8B%E5%AD%90"><span class="toc-text">2.3.2 举个例子</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#3-%E5%86%B3%E7%AD%96%E6%A0%91%E7%9A%84%E7%94%9F%E6%88%90"><span class="toc-text">3 决策树的生成</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#3-1-%E4%BB%8B%E7%BB%8D"><span class="toc-text">3.1 介绍</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-2-ID3%E7%AE%97%E6%B3%95"><span class="toc-text">3.2 ID3算法</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-1-ID3%E7%AE%97%E6%B3%95%E6%A0%B8%E5%BF%83"><span class="toc-text">3.2.1 ID3算法核心</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-2-%E7%AE%97%E6%B3%95%E8%BF%87%E7%A8%8B"><span class="toc-text">3.2.2 算法过程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-3-%E4%B8%BE%E4%B8%AA%E4%BE%8B%E5%AD%90"><span class="toc-text">3.2.3 举个例子</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-4-ID3%E7%AE%97%E6%B3%95%E7%9A%84%E4%B8%8D%E8%B6%B3"><span class="toc-text">3.2.4 ID3算法的不足</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-3-C4-5%E7%AE%97%E6%B3%95"><span class="toc-text">3.3 C4.5算法</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-3-1-C4-5%E7%AE%97%E6%B3%95%E7%9A%84%E4%B8%8D%E8%B6%B3"><span class="toc-text">3.3.1 C4.5算法的不足</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#4-%E6%80%BB%E7%BB%93"><span class="toc-text">4 总结</span></a></li></ol></div></p>
<h1 id="1-决策树模型介绍"><a href="#1-决策树模型介绍" class="headerlink" title="1 决策树模型介绍"></a>1 决策树模型介绍</h1><h2 id="1-1-决策树模型概述"><a href="#1-1-决策树模型概述" class="headerlink" title="1.1 决策树模型概述"></a>1.1 决策树模型概述</h2><p>   分类决策树模型是一种描述对实例进行分类的树形结构。决策树由结点和有向边组成。结点有两种类型：内部节点和叶节点，内部节点表示一个特征或属性，叶节点表示一个类。<br>   分类的时候，从根节点开始，当前节点设为根节点，当前节点必定是一种特征，根据实例的该特征的取值，向下移动，直到到达叶节点，将实例分到叶节点对应的类中。<br><img src="https://img-blog.csdnimg.cn/20200802172055879.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80OTMxMzMxOQ==,size_16,color_FFFFFF,t_70" alt="决策树模型"></p>
<h2 id="1-2-决策树与if-then规则"><a href="#1-2-决策树与if-then规则" class="headerlink" title="1.2 决策树与if-then规则"></a>1.2 决策树与if-then规则</h2><p>可以将决策树看成一个if-then规则的集合：由决策树的根节点到叶节点的每一条路径构建一条规则；路径上的内部结点的特征对应着if条件，叶节点对应着then结论。决策树的每一条路径都具有一个重要的性质：互斥且完备。这就是说，任何一个实例都被且仅被一条路径或规则覆盖。这里所谓覆盖是指实例的特征与路径上的特征一致或实例满足规则的条件。<br><em>举个例子：if(明天是晴天）then(我将出去玩)</em></p>
<h2 id="1-3-决策树主要优点"><a href="#1-3-决策树主要优点" class="headerlink" title="1.3 决策树主要优点"></a>1.3 决策树主要优点</h2><p>1.分类速度快；<br>2.具有可读性；<br>3.学习时，利用训练数据，根据损失函数最小化的原则建立决策树模型。预测时，对新数据集，利用决策树模型进行分类。</p>
<h2 id="1-4-主要步骤"><a href="#1-4-主要步骤" class="headerlink" title="1.4 主要步骤"></a>1.4 主要步骤</h2><p>1.特征选择问题<br>2.决策树的生成<br>3.决策树的剪枝</p>
<h1 id="2-特征选择"><a href="#2-特征选择" class="headerlink" title="2 特征选择"></a>2 特征选择</h1><h2 id="2-1-特征选择问题"><a href="#2-1-特征选择问题" class="headerlink" title="2.1 特征选择问题"></a>2.1 特征选择问题</h2><p>特征选择在于选取对训练集具有分类能力的特征。如果利用一个特征进行分类的结果与随即分类的结果没有很大差别，则称这个特征没有分类能力。通常特征选则的准则是信息增益或信息增益比。<br>特征选择是决定用哪个特征来划分特征空间。</p>
<h3 id="2-1-1-举个例子"><a href="#2-1-1-举个例子" class="headerlink" title="2.1.1 举个例子"></a>2.1.1 <em>举个例子</em></h3><p>下表（表5.1）是由15个样本组成的贷款申请训练数据。数据包括贷款申请人的4个特征（属性），具体信息如表所示：<img src="https://img-blog.csdnimg.cn/20200802174557798.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80OTMxMzMxOQ==,size_16,color_FFFFFF,t_70" alt="贷款申请样本数据集"><br>通过上表所给的训练数据构建一个贷款申请的决策树，用以对未来的贷款申请进行分类，即当新的客户提出贷款申请是，根据申请人的特征利用决策树决定是否批准贷款申请。<br><strong>在说明这个例子之前，必须先了解几个定义。</strong></p>
<h2 id="2-2-重要定义"><a href="#2-2-重要定义" class="headerlink" title="2.2 重要定义"></a>2.2 重要定义</h2><h3 id="2-2-1-熵"><a href="#2-2-1-熵" class="headerlink" title="2.2.1 熵"></a>2.2.1 熵</h3><p><img src="https://img-blog.csdnimg.cn/20200802180036468.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80OTMxMzMxOQ==,size_16,color_FFFFFF,t_70" alt="熵"><br>由熵的定义可知，熵只依赖与X的分布，而与X的取值无关，所以也可以将X的熵记作H（<em>p</em>）,即<img src="https://img-blog.csdnimg.cn/2020080218034198.png" alt="熵"></p>
<h3 id="2-2-2-条件熵"><a href="#2-2-2-条件熵" class="headerlink" title="2.2.2 条件熵"></a>2.2.2 条件熵</h3><p><img src="https://img-blog.csdnimg.cn/20200802180611704.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80OTMxMzMxOQ==,size_16,color_FFFFFF,t_70" alt="条件熵"></p>
<h3 id="2-2-3-信息增益"><a href="#2-2-3-信息增益" class="headerlink" title="2.2.3 信息增益"></a>2.2.3 信息增益</h3><p><img src="https://img-blog.csdnimg.cn/20200802180734432.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80OTMxMzMxOQ==,size_16,color_FFFFFF,t_70" alt="信息增益"><br>一般地，熵H(Y)与条件熵H(Y|X)之差成为互信息。决策树学习中的信息增益等价于训练数据集中类与特征的互信息。</p>
<h2 id="2-3-信息增益的算法"><a href="#2-3-信息增益的算法" class="headerlink" title="2.3 信息增益的算法"></a>2.3 信息增益的算法</h2><h3 id="2-3-1-算法过程"><a href="#2-3-1-算法过程" class="headerlink" title="2.3.1 算法过程"></a>2.3.1 算法过程</h3><p><img src="https://img-blog.csdnimg.cn/20200802181234549.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80OTMxMzMxOQ==,size_16,color_FFFFFF,t_70" alt="信息增益的算法过程"></p>
<h3 id="2-3-2-举个例子"><a href="#2-3-2-举个例子" class="headerlink" title="2.3.2 举个例子"></a>2.3.2 <em>举个例子</em></h3><p><img src="https://img-blog.csdnimg.cn/20200802181403214.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80OTMxMzMxOQ==,size_16,color_FFFFFF,t_70" alt="计算过程"><img src="https://img-blog.csdnimg.cn/20200802181442245.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80OTMxMzMxOQ==,size_16,color_FFFFFF,t_70" alt="例子"></p>
<h1 id="3-决策树的生成"><a href="#3-决策树的生成" class="headerlink" title="3 决策树的生成"></a>3 决策树的生成</h1><h2 id="3-1-介绍"><a href="#3-1-介绍" class="headerlink" title="3.1 介绍"></a>3.1 介绍</h2><p>   根据选择的特征评估标准，从上至下递归地生成子节点，直到数据集不可分则停止，决策树停止生长。这个过程实际上就是使用满足划分准则的特征不断的将数据集划分成纯度更高，不确定性更小的子集的过程。对于当前数据集的每一次划分，都希望根据某个特征划分之后的各个子集的纯度更高，不确定性更小。<br>    决策树生成算法不唯一，这里仅介绍两种算法——ID3算法和C4.5算法。</p>
<h2 id="3-2-ID3算法"><a href="#3-2-ID3算法" class="headerlink" title="3.2 ID3算法"></a>3.2 ID3算法</h2><h3 id="3-2-1-ID3算法核心"><a href="#3-2-1-ID3算法核心" class="headerlink" title="3.2.1 ID3算法核心"></a>3.2.1 ID3算法核心</h3><p>核心：是在决策树各个节点上应用**<strong>信息增益准则**</strong>选择特征递归地构建决策树。</p>
<h3 id="3-2-2-算法过程"><a href="#3-2-2-算法过程" class="headerlink" title="3.2.2 算法过程"></a>3.2.2 算法过程</h3><p>算法的过程为：<br>　　　1）初始化信息增益的阈值ϵ<br>　　　2）判断样本是否为同一类Di ，如果是则返回单节点树T。标记类别为Di。<br>　　　3）判断特征是否为空，如果是则返回单节点树T，标记类别为样本中输出类别D实例数最多的类别。<br>　　　4）计算A中的各个特征（一共n个）对输出D的信息增益，选择信息增益最大的特征Ag。<br>　　　5）如果Ag的信息增益小于阈值ϵ，则返回单节点树T，标记类别为样本中输出类别D实例数最多的类别。<br>　　　6）否则，按特征Ag的不同取值Agi将对应的样本输出D分成不同的类别Di。每个类别产生一个子节点。对应特征值为Agi。返回增加了节点的数T。<br>　　　7）对于所有的子节点，令D=Di,A=A−{Ag} ，递归调用2-6步，得到子树Ti并返回。</p>
<h3 id="3-2-3-举个例子"><a href="#3-2-3-举个例子" class="headerlink" title="3.2.3 举个例子"></a>3.2.3 <em>举个例子</em></h3><p>用ID3算法构建表5.1的决策树过程如下：<img src="https://img-blog.csdnimg.cn/20200802182533696.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80OTMxMzMxOQ==,size_16,color_FFFFFF,t_70" alt="例子"><br>构建决策树结果：<br><img src="https://img-blog.csdnimg.cn/2020080218271422.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80OTMxMzMxOQ==,size_16,color_FFFFFF,t_70" alt="决策树"></p>
<h3 id="3-2-4-ID3算法的不足"><a href="#3-2-4-ID3算法的不足" class="headerlink" title="3.2.4 ID3算法的不足"></a>3.2.4 ID3算法的不足</h3><p>  ID3算法虽然提出了新思路，但是还是有很多值得改进的地方。　　</p>
<ol>
<li>ID3没有考虑连续特征，比如长度，密度都是连续值，无法在ID3运用。这大大限制了ID3的用途。</li>
<li>ID3采用信息增益大的特征优先建立决策树的节点。很快就被人发现，在相同条件下，取值比较多的特征比取值少的特征信息增益大。比如一个变量有2个值，各为1/2，另一个变量为3个值，各为1/3，其实他们都是完全不确定的变量，但是取3个值的比取2个值的信息增益大。</li>
<li>ID3算法对于缺失值的情况没有做考虑。</li>
<li>没有考虑过拟合的问题。</li>
</ol>
<h2 id="3-3-C4-5算法"><a href="#3-3-C4-5算法" class="headerlink" title="3.3 C4.5算法"></a>3.3 C4.5算法</h2><p>C4.5算法与ID3算法很相似，C4.5算法仅仅是对ID3算法做了改进，在生成决策树过程中采用<strong>信息增益比</strong>来选择特征算法过程没有变化，这里不再赘述。</p>
<h3 id="3-3-1-C4-5算法的不足"><a href="#3-3-1-C4-5算法的不足" class="headerlink" title="3.3.1 C4.5算法的不足"></a>3.3.1 C4.5算法的不足</h3><p>   C4.5虽然改进了ID3算法的几个主要的问题，仍然有优化的空间。</p>
<ol>
<li>由于决策树算法非常容易过拟合，因此对于生成的决策树必须要进行剪枝。剪枝的算法有非常多，C4.5的剪枝方法有优化的空间。思路主要是两种，一种是预剪枝，即在生成决策树的时候就决定是否剪枝。另一个是后剪枝，即先生成决策树，再通过交叉验证来剪枝。<ol start="2">
<li>C4.5生成的是多叉树，即一个父节点可以有多个节点。很多时候，在计算机中二叉树模型会比多叉树运算效率高。如果采用二叉树，可以提高效率。</li>
<li>C4.5只能用于分类，如果能将决策树用于回归的话可以扩大它的使用范围。</li>
<li>C4.5由于使用了熵模型，里面有大量的耗时的对数运算,如果是连续值还有大量的排序运算。如果能够加以模型简化可以减少运算强度但又不牺牲太多准确性的话，那就更好了。<br>　   这4个问题在CART树里面部分加以了改进。所以目前如果不考虑集成学习话，在普通的决策树算法里，CART算法算是比较优的算法了。<h1 id="4-总结"><a href="#4-总结" class="headerlink" title="4 总结"></a>4 总结</h1>这篇文章仅简单介绍了决策树的基本内容，主要是决策树的特征选择和生成两部分，后续会继续介绍决策树的剪枝和CART这个比较方便的算法。</li>
</ol>
</li>
</ol>

      
       <hr><span style="font-style: italic;color: gray;"> 转载请注明来源，欢迎对文章中的引用来源进行考证，欢迎指出任何有错误或不够清晰的表达。可以在下面评论区评论，也可以邮件至 1395876210@qq.com </span>
    </div>
</article>


<p>
    <a  class="dashang" onclick="dashangToggle()">赏</a>
</p>






    




    </div>
    <div class="copyright">
        <p class="footer-entry">
    ©2016-2020 ting-ting-he
</p>
<p class="footer-entry">Built with <a href="https://hexo.io/" target="_blank">Hexo</a> and <a href="https://github.com/yelog/hexo-theme-3-hexo" target="_blank">3-hexo</a> theme</p>

    </div>
    <div class="full-toc">
        <button class="full" data-title="切换全屏 快捷键 s"><span class="min "></span></button>
<a class="" id="rocket" ></a>

    </div>
</div>

<div class="hide_box" onclick="dashangToggle()"></div>
<div class="shang_box">
    <a class="shang_close"  onclick="dashangToggle()">×</a>
    <div class="shang_tit">
        <p>喜欢就点赞,疼爱就打赏</p>
    </div>
    <div class="shang_payimg">
        <div class="pay_img">
            <img src="/img/alipay.jpg" class="alipay" title="扫码支持">
            <img src="/img/weixin.jpg" class="weixin" title="扫码支持">
        </div>
    </div>
    <div class="shang_payselect">
        <span><label><input type="radio" name="pay" checked value="alipay">支付宝</label></span><span><label><input type="radio" name="pay" value="weixin">微信</label></span>
    </div>
</div>


</body>
<script src="/js/jquery.pjax.js?v=1.1.0" ></script>

<script src="/js/script.js?v=1.1.0" ></script>
<script>
    var img_resize = 'default';
    function initArticle() {
        /*渲染对应的表格样式*/
        
            $("#post .pjax table").addClass("green_title");
        

        /*渲染打赏样式*/
        
        $("input[name=pay]").on("click", function () {
            if($("input[name=pay]:checked").val()=="weixin"){
                $(".shang_box .shang_payimg .pay_img").addClass("weixin_img");
            } else {
                $(".shang_box .shang_payimg .pay_img").removeClass("weixin_img");
            }
        })
        

        /*高亮代码块行号*/
        

        /*访问数量*/
        
        $.getScript("//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js");
        

        /*代码高亮，行号对齐*/
        $('.pre-numbering').css('line-height',$('.has-numbering').css('line-height'));

        
        
    }

    /*打赏页面隐藏与展示*/
    
    function dashangToggle() {
        $(".shang_box").fadeToggle();
        $(".hide_box").fadeToggle();
    }
    

</script>

<!--加入行号的高亮代码块样式-->

<!--自定义样式设置-->
<style>
    
    
    .nav {
        width: 542px;
    }
    .nav.fullscreen {
        margin-left: -542px;
    }
    .nav-left {
        width: 120px;
    }
    
    
    @media screen and (max-width: 1468px) {
        .nav {
            width: 492px;
        }
        .nav.fullscreen {
            margin-left: -492px;
        }
        .nav-left {
            width: 100px;
        }
    }
    
    
    @media screen and (max-width: 1024px) {
        .nav {
            width: 492px;
            margin-left: -492px
        }
        .nav.fullscreen {
            margin-left: 0;
        }
    }
    
    @media screen and (max-width: 426px) {
        .nav {
            width: 100%;
        }
        .nav-left {
            width: 100%;
        }
    }
    
    
    .nav-right .title-list nav a .post-title, .nav-right .title-list #local-search-result a .post-title {
        color: #383636;
    }
    
    
    .nav-right .title-list nav a .post-date, .nav-right .title-list #local-search-result a .post-date {
        color: #5e5e5f;
    }
    
    
    .nav-right nav a.hover, #local-search-result a.hover{
        background-color: #e2e0e0;
    }
    
    

    /*列表样式*/
    

    /* 背景图样式 */
    
    


    /*引用块样式*/
    

    /*文章列表背景图*/
    

    
</style>







</html>
